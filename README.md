# MobileVLA: Vision Language Action Model for Mobile Devices

[![Apache License](https://img.shields.io/badge/license-Apache-green.svg)](https://opensource.org/licenses/MIT) [![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg)](https://github.com/996icu/996.ICU/blob/master/LICENSE)

MobileVLA is expected to be a smart assistant by deploying on mobile devices.



## Prerequisite:

### Step 0

Follow the instructions in the [MobileVLM](https://github.com/Meituan-AutoML/MobileVLM) and [CALVIN](https://github.com/mees/calvin) to download the necessary dataset and VLM pretrained Models.

Download the [CALVIN](https://github.com/mees/calvin) dataset

```
cd $HULC_ROOT/dataset
sh download_data.sh D | ABC | ABCD | debug
```

Download the released [MobileVLM](https://github.com/Meituan-AutoML/MobileVLM) model:



## Acknowledgment

#### CALVIN

Original: https://github.com/mees/calvin License: [MIT](https://github.com/mees/calvin/blob/main/LICENSE)

#### ByteDance RoboFlamingo

Original: https://github.com/RoboFlamingo/RoboFlamingo License: [MIT](https://github.com/RoboFlamingo/RoboFlamingo/blob/main/LICENSE)

#### Meituan MobileVLM

Original: https://github.com/Meituan-AutoML/MobileVLM License: [Apache-2.0](https://github.com/Meituan-AutoML/MobileVLM/blob/main/LICENSE)
